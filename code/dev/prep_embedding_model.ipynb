{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ddeb93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyannote.audio import Model\n",
    "import wave\n",
    "from pyannote.audio import Inference\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e60ac8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/c6335d8f1cd77b30084387468a6cf26fea90009b/pytorch_model.bin`\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.2.7 to v2.2.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../.cache/torch/pyannote/models--pyannote--embedding/snapshots/c6335d8f1cd77b30084387468a6cf26fea90009b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.2.0. Bad things might happen unless you revert torch to 1.x.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.8.1+cu102, yours is 2.2.0. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "model = Model.from_pretrained(\"pyannote/embedding\", \n",
    "                              use_auth_token=os.environ['HF_AUTH'])\n",
    "inference = Inference(model, window=\"whole\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7d1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../data/speech_embedding_data/\"\n",
    "output_path = \"../data/speech_embedding_models/\"\n",
    "wav_files = [f for f in os.listdir(input_path) if f.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213423b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mccain.wav\n",
      "clinton.wav\n",
      "romney.wav\n",
      "multi.wav\n",
      "trump.wav\n",
      "kerry.wav\n",
      "bush.wav\n",
      "other.wav\n",
      "biden.wav\n",
      "obama.wav\n",
      "gore.wav\n"
     ]
    }
   ],
   "source": [
    "for wav_file in wav_files:\n",
    "    print(wav_file)\n",
    "    wav_file_path = os.path.join(input_path, wav_file)\n",
    "    embedding_path = Path(wav_file_path).stem\n",
    "    embedding = inference(wav_file_path)\n",
    "    np.save(output_path + embedding_path, embedding, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
